# pipeline_run.py
# Run on GitHub Actions: reads artists from Google Drive (Sheet/Excel),
# fetches SoundCloud metrics, writes XLSX to outputs/, uploads to Drive, notifies Telegram.

import os, re, time, base64, json, io
from datetime import datetime
from zoneinfo import ZoneInfo
from urllib.parse import urlencode

import requests
import pandas as pd

from google.oauth2.credentials import Credentials
from googleapiclient.discovery import build
from googleapiclient.http import MediaIoBaseDownload, MediaFileUpload
from googleapiclient.errors import HttpError

# ------------ Config from ENV (GitHub Secrets) ------------
SC_CLIENT_ID     = os.getenv("SC_CLIENT_ID", "")
SC_CLIENT_SECRET = os.getenv("SC_CLIENT_SECRET", "")

GDRIVE_TOKEN_JSON_PATH = os.getenv("GDRIVE_TOKEN_JSON_PATH", "token.json")
DRIVE_FOLDER_ID        = os.getenv("DRIVE_FOLDER_ID", "")
# ÛŒÚ©ÛŒ Ø§Ø² Ø§ÛŒÙ† Ø¯Ùˆ ØªØ§ Ú©ÙØ§ÛŒØª Ù…ÛŒâ€ŒÚ©Ù†Ø¯ (ØªØ±Ø¬ÛŒØ­: Google Sheet)
GSHEET_ARTISTS_FILE_ID = os.getenv("GSHEET_ARTISTS_FILE_ID")  # Google Sheet â†’ CSV
ARTISTS_DRIVE_FILE_ID  = os.getenv("ARTISTS_DRIVE_FILE_ID")   # Excel/CSV Ø±ÙˆÛŒ Drive

TELEGRAM_BOT_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN", "")
TELEGRAM_CHAT_ID   = os.getenv("TELEGRAM_CHAT_ID", "")

OUT_DIR = "outputs"
TZ_IRAN = ZoneInfo("Asia/Tehran")
BATCH_SIZE = 50

SC_API   = "https://api.soundcloud.com"
SC_TOKEN = "https://secure.soundcloud.com/oauth/token"
SC_TIMEOUT = 30
RETRY_STATUS = {429, 500, 502, 503, 504}

# ----------------- utils -----------------
def iran_now(): return datetime.now(TZ_IRAN)
def ts_for_filename(): return iran_now().strftime("%Y%m%d_%H%M%S")

def tg_send_text(text: str):
    if not TELEGRAM_BOT_TOKEN or not TELEGRAM_CHAT_ID: return
    try:
        r = requests.post(
            f"https://api.telegram.org/bot{TELEGRAM_BOT_TOKEN}/sendMessage",
            data={"chat_id": TELEGRAM_CHAT_ID, "text": text, "disable_web_page_preview": True},
            timeout=60
        )
        if not r.ok: print("âš ï¸ Telegram error:", r.text)
    except Exception as e:
        print("âš ï¸ Telegram exception:", e)

def tg_send_document(file_path: str, caption: str = ""):
    if not TELEGRAM_BOT_TOKEN or not TELEGRAM_CHAT_ID: return
    try:
        with open(file_path, "rb") as f:
            r = requests.post(
                f"https://api.telegram.org/bot{TELEGRAM_BOT_TOKEN}/sendDocument",
                data={"chat_id": TELEGRAM_CHAT_ID, "caption": caption},
                files={"document": (os.path.basename(file_path), f)},
                timeout=120
            )
        if not r.ok: print("âš ï¸ Telegram doc error:", r.text)
    except Exception as e:
        print("âš ï¸ Telegram doc exception:", e)

# ----------------- Google Drive -----------------
def build_drive():
    # Ø§Ø² Ù‡Ù…Ø§Ù† scopeÙ‡Ø§ÛŒ Ø°Ø®ÛŒØ±Ù‡â€ŒØ´Ø¯Ù‡ Ø¯Ø± token.json Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ… (Ø¨Ø¯ÙˆÙ† override)
    creds = Credentials.from_authorized_user_file(GDRIVE_TOKEN_JSON_PATH)
    print("Drive token scopes:", getattr(creds, "scopes", None))
    return build("drive", "v3", credentials=creds, cache_discovery=False)

def download_sheet_as_csv(service, file_id: str) -> pd.DataFrame:
    # export first sheet as CSV
    req = service.files().export(fileId=file_id, mimeType="text/csv")
    buf = io.BytesIO()
    downloader = MediaIoBaseDownload(buf, req)
    done = False
    while not done:
        status, done = downloader.next_chunk()
    buf.seek(0)
    return pd.read_csv(buf)

def download_drive_file(service, file_id: str) -> bytes:
    req = service.files().get_media(fileId=file_id)
    buf = io.BytesIO()
    downloader = MediaIoBaseDownload(buf, req)
    done = False
    while not done:
        status, done = downloader.next_chunk()
    return buf.getvalue()

def drive_upload(service, file_path: str, parent_id: str, share_anyone=True):
    meta = {"name": os.path.basename(file_path), "parents": [parent_id]}
    media = MediaFileUpload(file_path, resumable=True)
    file = service.files().create(body=meta, media_body=media, fields="id, webViewLink").execute()
    if share_anyone:
        try:
            service.permissions().create(fileId=file["id"], body={"role":"reader","type":"anyone"}).execute()
        except HttpError:
            pass
    return file

# ----------------- Artists input loader -----------------
URN_CANDIDATES = [
    "artist_urn","urn","user_urn","soundcloud_urn",
    "artist_id","user_id","Ø´Ù†Ø§Ø³Ù‡","Ø´Ù†Ø§Ø³Ù‡ ÛŒ Ø§Ø±ØªÛŒØ³Øª","Ø´Ù†Ø§Ø³Ù‡ Ø§Ø±ØªÛŒØ³Øª"
]
INPUT_NAME_CANDIDATES = [
    "artist_input_name","name_input","my_name","artist_alias",
    "Ø§Ø³Ù… Ù…Ù†","Ù†Ø§Ù… ÙˆØ±ÙˆØ¯ÛŒ","Ù†Ø§Ù…ÛŒ Ú©Ù‡ Ù…Ù† Ú¯Ø°Ø§Ø´ØªÙ…"
]
SC_NAME_CANDIDATES = [
    "artist_name","username","resolved_name","soundcloud_username",
    "Ø§Ø³Ù… Ø³Ø§Ù†Ø¯Ú©Ù„Ø§Ø¯","Ù†Ø§Ù… Ø³Ø§Ù†Ø¯Ú©Ù„Ø§Ø¯","Ù†Ø§Ù… Ú¯Ø±ÙØªÙ‡ Ø´Ø¯Ù‡"
]

def _find_col(df, candidates, required=True):
    for cand in candidates:
        for col in df.columns:
            if col.strip().lower() == cand.strip().lower():
                return col
    if required:
        raise ValueError(f"Ø³ØªÙˆÙ† Ù„Ø§Ø²Ù… Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯. ÛŒÚ©ÛŒ Ø§Ø² Ø§ÛŒÙ†â€ŒÙ‡Ø§ Ø¨Ø§ÛŒØ¯ Ø¨Ø§Ø´Ø¯: {candidates}\nÙ…ÙˆØ¬ÙˆØ¯: {list(df.columns)}")
    return None

def load_artists_df_from_drive() -> pd.DataFrame:
    service = build_drive()
    if GSHEET_ARTISTS_FILE_ID:
        print(f"  using source: GSHEET (file_id={GSHEET_ARTISTS_FILE_ID})")  # â† Ø®Ø· Ø¬Ø¯ÛŒØ¯
        df = download_sheet_as_csv(service, GSHEET_ARTISTS_FILE_ID)
    elif ARTISTS_DRIVE_FILE_ID:
        print(f"  using source: DRIVE FILE (file_id={ARTISTS_DRIVE_FILE_ID})")  # â† Ø®Ø· Ø¬Ø¯ÛŒØ¯
        data = download_drive_file(service, ARTISTS_DRIVE_FILE_ID)
        try:
            df = pd.read_excel(io.BytesIO(data))
        except Exception:
            df = pd.read_csv(io.BytesIO(data))
    else:
        raise RuntimeError("Ù‡ÛŒÚ† File ID Ø¨Ø±Ø§ÛŒ Ù„ÛŒØ³Øª Ø¢Ø±ØªÛŒØ³Øªâ€ŒÙ‡Ø§ ØªÙ†Ø¸ÛŒÙ… Ù†Ø´Ø¯Ù‡ Ø§Ø³Øª.")

    col_urn = _find_col(df, URN_CANDIDATES, required=True)
    col_input_name = _find_col(df, INPUT_NAME_CANDIDATES, required=False)
    col_sc_name    = _find_col(df, SC_NAME_CANDIDATES, required=False)

    df[col_urn] = df[col_urn].astype(str).str.strip()
    mask_num = df[col_urn].str.fullmatch(r"\d+")
    df.loc[mask_num, col_urn] = df.loc[mask_num, col_urn].map(lambda x: f"soundcloud:users:{x}")
    df = df.dropna(subset=[col_urn])
    df = df[df[col_urn] != ""].drop_duplicates(subset=[col_urn]).reset_index(drop=True)

    if col_input_name and "artist_input_name" not in df.columns:
        df.rename(columns={col_input_name: "artist_input_name"}, inplace=True)
    if col_sc_name and "artist_name" not in df.columns:
        df.rename(columns={col_sc_name: "artist_name"}, inplace=True)
    if col_urn != "artist_urn":
        df.rename(columns={col_urn: "artist_urn"}, inplace=True)
    return df



def load_artists_any() -> pd.DataFrame:
    """
    ÙÙ‚Ø· Ø§Ø² Google Sheet/Drive Ù…ÛŒâ€ŒØ®ÙˆØ§Ù†Ø¯. Ø§Ú¯Ø± Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†Ø¨ÙˆØ¯ â†’ Ø®Ø·Ø§ Ù…ÛŒâ€ŒØ¯Ù‡Ø¯ (CI fail-fast).
    """
    try:
        return load_artists_df_from_drive()
    except Exception as e:
        raise RuntimeError(
            f"artists load failed from Drive/Sheet: {e}\n"
            "Set GSHEET_ARTISTS_FILE_ID (Google Sheet) ÛŒØ§ ARTISTS_DRIVE_FILE_ID (Drive file) "
            "Ùˆ Ù…Ø·Ù…Ø¦Ù† Ø´Ùˆ token.json Ø¯Ø±Ø³Øª Ù†ÙˆØ´ØªÙ‡ Ø´Ø¯Ù‡."
        )


# ----------------- SoundCloud -----------------
def sc_get_access_token():
    hdr = {
        "Authorization": "Basic " + base64.b64encode(f"{SC_CLIENT_ID}:{SC_CLIENT_SECRET}".encode("utf-8")).decode("utf-8"),
        "Content-Type": "application/x-www-form-urlencoded",
    }
    r = requests.post(SC_TOKEN, headers=hdr, data={"grant_type":"client_credentials"}, timeout=SC_TIMEOUT)
    r.raise_for_status()
    return r.json()["access_token"]

def sc_session(token: str):
    s = requests.Session()
    s.headers.update({"Authorization": f"Bearer {token}", "Accept":"application/json"})
    return s

def _sleep_backoff(attempt, retry_after=None):
    if retry_after:
        try: sec = float(retry_after)
        except: sec = 2.0
    else:
        sec = min(2.0 * (2 ** (attempt - 1)), 20.0)
    time.sleep(sec)

def sc_get_with_retry(session, url, params=None, max_retries=4):
    """
    GET Ø¨Ø§ retry Ù‡Ù… Ø¨Ø±Ø§ÛŒ status codeÙ‡Ø§ÛŒ Ù…ÙˆÙ‚Øª (429/5xx)
    Ù‡Ù… Ø¨Ø±Ø§ÛŒ Ø®Ø·Ø§Ù‡Ø§ÛŒ Ø´Ø¨Ú©Ù‡â€ŒØ§ÛŒ Ù…Ø«Ù„ Connection broken / IncompleteRead.
    """
    attempt = 1
    while True:
        try:
            resp = session.get(url, params=params, timeout=SC_TIMEOUT)
        except (requests.exceptions.ChunkedEncodingError,
                requests.exceptions.ConnectionError) as e:
            # Ø®Ø·Ø§Ù‡Ø§ÛŒ Ø´Ø¨Ú©Ù‡â€ŒØ§ÛŒ (Ù…Ø«Ù„ Ù‡Ù…ÙˆÙ† IncompleteRead Ú©Ù‡ Ø¯ÛŒØ¯ÛŒ)
            if attempt < max_retries:
                print(f"    âš ï¸ network error on {url} (attempt {attempt}): {e} â†’ retrying ...")
                _sleep_backoff(attempt)
                attempt += 1
                continue
            # Ø¨Ø¹Ø¯ Ø§Ø² Ú†Ù†Ø¯ ØªÙ„Ø§Ø´ Ù‡Ù†ÙˆØ² Ø®Ø±Ø§Ø¨ Ø§Ø³Øª â†’ Ø¨Ø¯Ù‡ Ø¨Ø±Ù‡ Ù„Ø§ÛŒÙ‡â€ŒÛŒ Ø¨Ø§Ù„Ø§ØªØ±
            raise

        # Ø§Ú¯Ø± Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ø§Ø±Ø³Ø§Ù„ Ø´Ø¯Ù‡ ÙˆÙ„ÛŒ status code Ù…ÙˆÙ‚ØªÛŒ Ø¨ÙˆØ¯ (429/5xx)
        if resp.status_code in RETRY_STATUS and attempt < max_retries:
            _sleep_backoff(attempt, resp.headers.get("Retry-After"))
            attempt += 1
            continue

        resp.raise_for_status()
        return resp


def sc_paged_get(session, url, params=None):
    params = dict(params or {})
    params.setdefault("linked_partitioning", True)
    out, next_url = [], f"{url}?{urlencode(params, doseq=True)}"
    while next_url:
        r = sc_get_with_retry(session, next_url)
        js = r.json()
        out.extend(js.get("collection") or [])
        next_url = js.get("next_href")
    return out

def sc_fetch_user(session, user_urn): return sc_get_with_retry(session, f"{SC_API}/users/{user_urn}").json()
def sc_user_tracks_list(session, user_urn): return sc_paged_get(session, f"{SC_API}/users/{user_urn}/tracks", {"limit":200})

def sc_hydrate_tracks(session, urns):
    out, total = [], len(urns)
    for i in range(0, total, BATCH_SIZE):
        batch = urns[i:i+BATCH_SIZE]
        q = {"urns": ",".join(batch), "limit": len(batch)}
        js = sc_get_with_retry(session, f"{SC_API}/tracks", q).json()
        items = js.get("collection") if isinstance(js, dict) else js
        if isinstance(items, list): out.extend(items)
        print(f"    â€¢ batch hydrated: {min(i+len(batch), total)}/{total}")
    return out

# ---- per-track metric validation + safe hydrate ----
METRIC_KEYS = ("playback_count", "favoritings_count", "comment_count", "reposts_count")

def track_metrics_any_missing(tr: dict) -> bool:
    """
    Ø§Ú¯Ø± Ø­ØªÛŒ ÛŒÚ©ÛŒ Ø§Ø² Ù…ØªØ±ÛŒÚ©â€ŒÙ‡Ø§ÛŒ Ù…Ù‡Ù… None Ø¨Ø§Ø´Ø¯ â†’ True
    (ØµÙØ± = Ø¯Ø§Ø¯Ù‡ Ù…Ø¹ØªØ¨Ø±. ÙÙ‚Ø· None Ù…Ø´Ú©Ù„ Ø§Ø³ØªØŒ ÛŒØ§ ÙˆÙ‚ØªÛŒ key ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯)
    """
    return any(tr.get(k) is None for k in METRIC_KEYS)

def sc_hydrate_tracks_safe(session, urns, artist_urn: str = "", max_rounds: int = 3):
    """
    1) Ù…Ø«Ù„ sc_hydrate_tracks Ù‡Ù…Ù‡â€ŒÛŒ URNÙ‡Ø§ Ø±Ø§ hydrate Ù…ÛŒâ€ŒÚ©Ù†Ø¯
    2) Ø¨Ø¹Ø¯ Ú†Ù†Ø¯ Ø¯ÙˆØ± ØªÙ„Ø§Ø´ Ù…ÛŒâ€ŒÚ©Ù†Ø¯:
       - ØªØ±Ú©â€ŒÙ‡Ø§ÛŒÛŒ Ú©Ù‡ Ø§ØµÙ„Ø§Ù‹ Ù†ÛŒØ§Ù…Ø¯Ù‡â€ŒØ§Ù†Ø¯ Ø±Ø§ Ø¯ÙˆØ¨Ø§Ø±Ù‡ hydrate Ú©Ù†Ø¯
       - ØªØ±Ú©â€ŒÙ‡Ø§ÛŒÛŒ Ú©Ù‡ Ù‡Ø± Ù…ØªØ±ÛŒÚ©â€ŒØ´Ø§Ù† None Ø§Ø³Øª Ø±Ø§ Ø¯ÙˆØ¨Ø§Ø±Ù‡ Ø¨Ú¯ÛŒØ±Ø¯
    """
    if not urns:
        return []

    # Ø¯ÙˆØ± Ø§ÙˆÙ„: hydrate Ù…Ø¹Ù…ÙˆÙ„ÛŒ
    tracks = sc_hydrate_tracks(session, urns)

    # map Ø¨Ø± Ø§Ø³Ø§Ø³ urn
    by_urn: dict[str, dict] = {}
    for t in tracks:
        u = t.get("urn")
        if u:
            by_urn[u] = t

    for round_idx in range(1, max_rounds + 1):
        missing_urns = set(urns) - set(by_urn.keys())
        bad_metric_urns = [u for u, t in by_urn.items() if track_metrics_any_missing(t)]
        to_fix = list(missing_urns.union(bad_metric_urns))

        if not to_fix:
            # Ù‡Ù…Ù‡ Ú†ÛŒØ² Ø§ÙˆÚ©ÛŒ Ø´Ø¯
            break

        print(
            f"    â†» metrics retry round {round_idx}: "
            f"{len(to_fix)} tracks Ù†ÛŒØ§Ø² Ø¨Ù‡ hydrate Ù…Ø¬Ø¯Ø¯ Ø¨Ø±Ø§ÛŒ Ø¢Ø±ØªÛŒØ³Øª {artist_urn}"
        )

        refreshed = sc_hydrate_tracks(session, to_fix)
        for t in refreshed:
            u = t.get("urn")
            if u:
                by_urn[u] = t

    # Ú¯Ø²Ø§Ø±Ø´ Ø§Ú¯Ø± Ù‡Ù†ÙˆØ² Ù…Ø´Ú©Ù„ Ø¯Ø§Ø±ÛŒÙ… (ÙÙ‚Ø· Ø±ÙˆÛŒ Ù„Ø§Ú¯)
    remaining_missing = set(urns) - set(by_urn.keys())
    remaining_bad = [u for u, t in by_urn.items() if track_metrics_any_missing(t)]

    if remaining_missing:
        print(
            f"    âš ï¸ Ø¨Ø¹Ø¯ Ø§Ø² retry Ù‡Ù†ÙˆØ² {len(remaining_missing)} ØªØ±Ú© hydrate Ù†Ø´Ø¯Ù‡ "
            f"(artist {artist_urn})"
        )
    if remaining_bad:
        print(
            f"    âš ï¸ Ø¨Ø¹Ø¯ Ø§Ø² retry Ù‡Ù†ÙˆØ² {len(remaining_bad)} ØªØ±Ú© Ù…ØªØ±ÛŒÚ© Ù†Ø§Ù‚Øµ Ø¯Ø§Ø±Ø¯ "
            f"(artist {artist_urn})"
        )

    # Ø®Ø±ÙˆØ¬ÛŒ Ø¨Ù‡ Ù‡Ù…Ø§Ù† ØªØ±ØªÛŒØ¨ Ù„ÛŒØ³Øª urnÙ‡Ø§
    return [by_urn[u] for u in urns if u in by_urn]



def sc_user_albums_with_tracks(session, user_urn):
    items = sc_paged_get(session, f"{SC_API}/users/{user_urn}/playlists", {"limit":200, "show_tracks":True})
    def is_album(p): return (p.get("set_type") or p.get("playlist_type") or "").lower() == "album"
    return [p for p in items if is_album(p)]

def extract_cover_sig(artwork_url: str | None):
    if not artwork_url: return None
    m = re.search(r'artworks-([A-Za-z0-9]+)-', artwork_url)
    if m: return m.group(1)
    base = artwork_url.rsplit('/', 1)[-1]
    return (base.split('.')[0] if base else None)

def build_album_map(albums):
    m = {}
    for alb in albums:
        info = {
            "album_urn": alb.get("urn"),
            "album_title": alb.get("title"),
            "album_permalink_url": alb.get("permalink_url"),
            "album_artwork_url": alb.get("artwork_url"),
            "album_cover_sig": extract_cover_sig(alb.get("artwork_url")),
        }
        for t in (alb.get("tracks") or []):
            tu = t.get("urn")
            if tu: m.setdefault(tu, []).append(info)
    return m

def flatten_album_fields(track_urn, album_map):
    albums = album_map.get(track_urn) or []
    if not albums:
        return {"in_album":False,"album_urns":None,"album_titles":None,"album_artwork_urls":None,"album_cover_sigs":None,"album_count":0}
    urns  = "; ".join([a.get("album_urn") or "" for a in albums if a.get("album_urn")])
    titles= "; ".join([a.get("album_title") or "" for a in albums if a.get("album_title")])
    arts  = "; ".join([a.get("album_artwork_url") or "" for a in albums if a.get("album_artwork_url")])
    sigs  = "; ".join([a.get("album_cover_sig") or "" for a in albums if a.get("album_cover_sig")])
    return {"in_album":True,"album_urns":urns or None,"album_titles":titles or None,"album_artwork_urls":arts or None,"album_cover_sigs":sigs or None,"album_count":len(albums)}

def compose_release_date(tr):
    y, m, d = tr.get("release_year"), tr.get("release_month"), tr.get("release_day")
    if y and m and d:
        try: return f"{int(y):04d}-{int(m):02d}-{int(d):02d}"
        except: return None
    return None

# ----------------- main -----------------
def main():
    start = time.time()
    print("Ø¯Ø± Ø­Ø§Ù„ Ú¯Ø±ÙØªÙ† ØªÙˆÚ©Ù† Ø§Ù¾ ...")
    token = sc_get_access_token()
    print("ØªÙˆÚ©Ù† OK âœ…\n")
    sess = sc_session(token)

    # ===== 1) Ø®ÙˆØ§Ù†Ø¯Ù† Ù„ÛŒØ³Øª Ø¢Ø±ØªÛŒØ³Øªâ€ŒÙ‡Ø§ =====
    print("Ø¯Ø± Ø­Ø§Ù„ Ø®ÙˆØ§Ù†Ø¯Ù† Ù„ÛŒØ³Øª Ø¢Ø±ØªÛŒØ³Øªâ€ŒÙ‡Ø§ ...")
    artists_df = load_artists_any()
    artists = artists_df["artist_urn"].tolist()

    print("ğŸ” loaded rows from Drive:", len(artists_df))
    print(artists_df.head(3).to_string(index=False))

    n = len(artists)
    print(f"ØªØ¹Ø¯Ø§Ø¯ Ø¢Ø±ØªÛŒØ³Øªâ€ŒÙ‡Ø§: {n}\n")

    # ===== 2) Ù…ØªØºÛŒØ±Ù‡Ø§ÛŒ ØªØ¬Ù…ÛŒØ¹ÛŒ =====
    track_rows: list[dict] = []
    album_rows: list[dict] = []
    artist_rows: list[dict] = []
    error_rows: list[dict] = []          # ÙÙ‚Ø· Ø®Ø·Ø§Ù‡Ø§ÛŒ Ø¨Ø¹Ø¯ Ø§Ø² Ù¾Ø§Ø³ Ø¯ÙˆÙ…

    tracks_total = 0
    albums_total = 0
    success_urns: set[str] = set()       # Ø¢Ø±ØªÛŒØ³Øªâ€ŒÙ‡Ø§ÛŒÛŒ Ú©Ù‡ Ø¯Ø± Ù†Ù‡Ø§ÛŒØª Ù…ÙˆÙÙ‚ Ø´Ø¯Ù†Ø¯
    retry_candidates: list[tuple[str, str | None]] = []  # (artist_urn, input_name)

    # ===== 3) Ù¾Ø§Ø³ Ø§ÙˆÙ„ Ø±ÙˆÛŒ Ù‡Ù…Ù‡â€ŒÛŒ Ø¢Ø±ØªÛŒØ³Øªâ€ŒÙ‡Ø§ =====
    for idx, artist_urn in enumerate(artists, start=1):
        input_name = artists_df.loc[idx-1, "artist_input_name"] if "artist_input_name" in artists_df.columns else None
        print(f"[{idx}/{n}] Ø¢Ø±ØªÛŒØ³Øª: {artist_urn}  ({input_name or '-'})")

        try:
            # --- user ---
            user = sc_fetch_user(sess, artist_urn)
            username = user.get("username")
            followers = user.get("followers_count")
            track_count_total = user.get("track_count")

            # Ø§Ú¯Ø± Ø¨Ù‡ Ù‡Ø± Ø¯Ù„ÛŒÙ„ track_count_total ÛŒØ§ followers Ø®Ø§Ù„ÛŒ Ø¨ÙˆØ¯ â†’ ÛŒÚ© Ø¨Ø§Ø± Ø¯ÛŒÚ¯Ø± user Ø±Ø§ Ù…ÛŒâ€ŒÚ¯ÛŒØ±ÛŒÙ…
            if track_count_total is None or followers is None:
                try:
                    user2 = sc_fetch_user(sess, artist_urn)
                    username = user2.get("username", username)
                    followers = user2.get("followers_count", followers)
                    track_count_total = user2.get("track_count", track_count_total)
                    print("    â„¹ï¸ user refetched Ø¨Ø±Ø§ÛŒ ØªÚ©Ù…ÛŒÙ„ track_count/followers")
                except Exception as e:
                    print(f"    âš ï¸ Ù†ØªÙˆÙ†Ø³ØªÛŒÙ… user Ø±Ø§ Ø¯ÙˆØ¨Ø§Ø±Ù‡ Ø¨Ú¯ÛŒØ±ÛŒÙ…: {e}")

            print(f"    user: {username} | followers: {followers} | track_count_total: {track_count_total}")

            # --- tracks list ---
            tracks_list = sc_user_tracks_list(sess, artist_urn)
            urns = [t.get("urn") for t in tracks_list if t.get("urn")]
            print(f"    tracks fetched (list): {len(urns)}")

            if track_count_total is not None and track_count_total != len(urns):
                print(
                    f"    âš ï¸ Ù‡Ø´Ø¯Ø§Ø±: track_count_total={track_count_total} "
                    f"Ø§Ù…Ø§ tracks_list={len(urns)} (Ù…Ù…Ú©Ù† Ø§Ø³Øª Ø¨Ù‡ Ø®Ø§Ø·Ø± ØªØ±Ú©â€ŒÙ‡Ø§ÛŒ private ÛŒØ§ Ø­Ø°Ùâ€ŒØ´Ø¯Ù‡ Ø¨Ø§Ø´Ø¯)"
                )

            
            # --- hydrate tracks + albums ---
            tracks_h = sc_hydrate_tracks_safe(sess, urns, artist_urn)
            albums   = sc_user_albums_with_tracks(sess, artist_urn)
            album_map= build_album_map(albums)

            # --- artist summary row ---
            artist_rows.append({
                "artist_urn": artist_urn,
                "artist_input_name": input_name,
                "artist_username": username,
                "followers": followers,
                "track_count_total": track_count_total,
            })

            # --- albums rows ---
            for alb in albums:
                album_rows.append({
                    "artist_urn": artist_urn, "artist_username": username,
                    "album_urn": alb.get("urn"), "album_title": alb.get("title"),
                    "album_permalink_url": alb.get("permalink_url"),
                    "album_artwork_url": alb.get("artwork_url"),
                    "album_cover_sig": extract_cover_sig(alb.get("artwork_url")),
                    "album_track_count": len(alb.get("tracks") or []),
                })

            # --- tracks rows ---
            for tr in tracks_h:
                tr_urn = tr.get("urn")
                row = {
                    "artist_urn": artist_urn, "artist_username": username,
                    "followers": followers, "track_count_total": track_count_total,
                    "track_urn": tr_urn, "track_title": tr.get("title"),
                    "permalink_url": tr.get("permalink_url"),
                    "artwork_url": tr.get("artwork_url"),
                    "track_cover_sig": extract_cover_sig(tr.get("artwork_url")),
                    "playback_count": tr.get("playback_count"),
                    "likes_count": tr.get("favoritings_count"),
                    "comment_count": tr.get("comment_count"),
                    "reposts_count": tr.get("reposts_count"),
                    "access": tr.get("access"), "streamable": tr.get("streamable"),
                    "created_at": tr.get("created_at"),
                    "release_date": compose_release_date(tr),
                    "release_year": tr.get("release_year"),
                    "release_month": tr.get("release_month"),
                    "release_day": tr.get("release_day"),
                }
                row.update(flatten_album_fields(tr_urn, album_map))
                track_rows.append(row)

            tracks_total += len(tracks_h)
            albums_total += len(albums)
            success_urns.add(artist_urn)

        except requests.HTTPError as e:
            status = getattr(e.response, "status_code", None)
            try:
                msg = e.response.json()
            except Exception:
                msg = str(e)
            print(f"    âŒ HTTPError {status} Ø¯Ø± Ù¾Ø§Ø³ Ø§ÙˆÙ„ â†’ Ø¨Ø±Ø§ÛŒ retry Ù†Ú¯Ù‡ Ù…ÛŒâ€ŒØ¯Ø§Ø±ÛŒÙ…")
            retry_candidates.append((artist_urn, input_name))

        except Exception as e:
            print(f"    âŒ Error Ø¯Ø± Ù¾Ø§Ø³ Ø§ÙˆÙ„ ({artist_urn}): {e} â†’ Ø¨Ø±Ø§ÛŒ retry Ù†Ú¯Ù‡ Ù…ÛŒâ€ŒØ¯Ø§Ø±ÛŒÙ…")
            retry_candidates.append((artist_urn, input_name))

    
    # ===== 4) Ù¾Ø§Ø³ Ø¯ÙˆÙ… (retry) ÙÙ‚Ø· Ø±ÙˆÛŒ Ø¢Ø±ØªÛŒØ³Øªâ€ŒÙ‡Ø§ÛŒ Ø®Ø·Ø§Ø¯Ø§Ø± =====
    if retry_candidates:
        print(f"\n=== âœ³ï¸ Ø´Ø±ÙˆØ¹ Ø¯ÙˆØ± Ø¯ÙˆÙ… Ø¨Ø±Ø§ÛŒ {len(retry_candidates)} Ø¢Ø±ØªÛŒØ³Øª Ø®Ø·Ø§Ø¯Ø§Ø± ===")
        for r_idx, (artist_urn, input_name) in enumerate(retry_candidates, start=1):
            print(f"[retry {r_idx}/{len(retry_candidates)}] Ø¢Ø±ØªÛŒØ³Øª: {artist_urn}  ({input_name or '-'})")
            try:
                # --- user (Ø¨Ø§ Ú©Ù†ØªØ±Ù„ followers Ùˆ track_count_total Ù…Ø«Ù„ Ù¾Ø§Ø³ Ø§ÙˆÙ„) ---
                user = sc_fetch_user(sess, artist_urn)
                username = user.get("username")
                followers = user.get("followers_count")
                track_count_total = user.get("track_count")

                if track_count_total is None or followers is None:
                    try:
                        user2 = sc_fetch_user(sess, artist_urn)
                        username = user2.get("username", username)
                        followers = user2.get("followers_count", followers)
                        track_count_total = user2.get("track_count", track_count_total)
                        print("    [retry] â„¹ï¸ user refetched Ø¨Ø±Ø§ÛŒ ØªÚ©Ù…ÛŒÙ„ track_count/followers")
                    except Exception as e:
                        print(f"    [retry] âš ï¸ Ù†ØªÙˆÙ†Ø³ØªÛŒÙ… user Ø±Ø§ Ø¯ÙˆØ¨Ø§Ø±Ù‡ Ø¨Ú¯ÛŒØ±ÛŒÙ…: {e}")

                print(f"    [retry] user: {username} | followers: {followers} | track_count_total: {track_count_total}")

                # --- tracks list ---
                tracks_list = sc_user_tracks_list(sess, artist_urn)
                urns = [t.get("urn") for t in tracks_list if t.get("urn")]
                print(f"    [retry] tracks fetched (list): {len(urns)}")

                if track_count_total is not None and track_count_total != len(urns):
                    print(
                        f"    [retry] âš ï¸ Ù‡Ø´Ø¯Ø§Ø±: track_count_total={track_count_total} "
                        f"Ø§Ù…Ø§ tracks_list={len(urns)} (Ù…Ù…Ú©Ù† Ø§Ø³Øª Ø¨Ù‡ Ø®Ø§Ø·Ø± ØªØ±Ú©â€ŒÙ‡Ø§ÛŒ private ÛŒØ§ Ø­Ø°Ùâ€ŒØ´Ø¯Ù‡ Ø¨Ø§Ø´Ø¯)"
                    )

                # --- hydrate tracks + albums (Ù†Ø³Ø®Ù‡â€ŒÛŒ safe) ---
                tracks_h = sc_hydrate_tracks_safe(sess, urns, artist_urn)
                albums   = sc_user_albums_with_tracks(sess, artist_urn)
                album_map= build_album_map(albums)

                # --- Ø¬Ù…Ø¹â€ŒÚ©Ø±Ø¯Ù† Ø®Ø±ÙˆØ¬ÛŒâ€ŒÙ‡Ø§ ---
                artist_rows.append({
                    "artist_urn": artist_urn,
                    "artist_input_name": input_name,
                    "artist_username": username,
                    "followers": followers,
                    "track_count_total": track_count_total,
                })
                for alb in albums:
                    album_rows.append({
                        "artist_urn": artist_urn, "artist_username": username,
                        "album_urn": alb.get("urn"), "album_title": alb.get("title"),
                        "album_permalink_url": alb.get("permalink_url"),
                        "album_artwork_url": alb.get("artwork_url"),
                        "album_cover_sig": extract_cover_sig(alb.get("artwork_url")),
                        "album_track_count": len(alb.get("tracks") or []),
                    })
                for tr in tracks_h:
                    tr_urn = tr.get("urn")
                    row = {
                        "artist_urn": artist_urn, "artist_username": username,
                        "followers": followers, "track_count_total": track_count_total,
                        "track_urn": tr_urn, "track_title": tr.get("title"),
                        "permalink_url": tr.get("permalink_url"),
                        "artwork_url": tr.get("artwork_url"),
                        "track_cover_sig": extract_cover_sig(tr.get("artwork_url")),
                        "playback_count": tr.get("playback_count"),
                        "likes_count": tr.get("favoritings_count"),
                        "comment_count": tr.get("comment_count"),
                        "reposts_count": tr.get("reposts_count"),
                        "access": tr.get("access"), "streamable": tr.get("streamable"),
                        "created_at": tr.get("created_at"),
                        "release_date": compose_release_date(tr),
                        "release_year": tr.get("release_year"),
                        "release_month": tr.get("release_month"),
                        "release_day": tr.get("release_day"),
                    }
                    row.update(flatten_album_fields(tr_urn, album_map))
                    track_rows.append(row)

                tracks_total += len(tracks_h)
                albums_total += len(albums)
                success_urns.add(artist_urn)
                print("    âœ… retry Ù…ÙˆÙÙ‚ Ø¨ÙˆØ¯")

            except requests.HTTPError as e:
                status = getattr(e.response, "status_code", None)
                try:
                    msg = e.response.json()
                except Exception:
                    msg = str(e)
                print(f"    âŒ HTTPError {status} Ø¯Ø± Ù¾Ø§Ø³ Ø¯ÙˆÙ… â†’ Ø§ÛŒÙ† ÛŒÚ©ÛŒ ÙˆØ§Ù‚Ø¹Ø§Ù‹ Ø®Ø·Ø§Ø³Øª")
                error_rows.append({
                    "timestamp": iran_now().isoformat(timespec="seconds"),
                    "artist_urn": artist_urn,
                    "artist_input_name": input_name,
                    "step": "retry_http",
                    "http_status": status,
                    "message": json.dumps(msg, ensure_ascii=False) if isinstance(msg, dict) else str(msg),
                })

            except Exception as e:
                print(f"    âŒ Error Ø¯Ø± Ù¾Ø§Ø³ Ø¯ÙˆÙ… ({artist_urn}): {e}")
                error_rows.append({
                    "timestamp": iran_now().isoformat(timespec="seconds"),
                    "artist_urn": artist_urn,
                    "artist_input_name": input_name,
                    "step": "retry_exception",
                    "http_status": None,
                    "message": str(e),
                })

    # ===== 5) Ø³Ø§Ø®Øª DataFrameÙ‡Ø§ =====
    df_tracks  = pd.DataFrame(track_rows)
    df_albums  = pd.DataFrame(album_rows)
    df_artists = pd.DataFrame(artist_rows)
    df_errors  = pd.DataFrame(error_rows)

    elapsed = time.time() - start
    snapshot_date = iran_now().strftime("%Y-%m-%d")
    timestamp     = iran_now().strftime("%Y-%m-%d %H:%M:%S")

    ok_count     = len(success_urns)
    fail_count   = n - ok_count
    errors_total = int(len(df_errors))

    meta = pd.DataFrame([{
        "snapshot_date": snapshot_date,
        "timestamp": timestamp,
        "run_seconds": round(elapsed, 2),
        "artists_in": n,
        "artists_ok": ok_count,
        "artists_failed": fail_count,
        "tracks_total": int(tracks_total),
        "albums_total": int(albums_total),
        "errors_total": errors_total,
    }])

    # ===== 6) Ø°Ø®ÛŒØ±Ù‡ Ø§Ú©Ø³Ù„ =====
    os.makedirs(OUT_DIR, exist_ok=True)
    out_xlsx = os.path.join(OUT_DIR, f"soundcloud_batch_{ts_for_filename()}.xlsx")
    with pd.ExcelWriter(out_xlsx, engine="openpyxl") as w:
        df_tracks.to_excel(w, index=False, sheet_name="tracks")
        df_albums.to_excel(w, index=False, sheet_name="albums")
        df_artists.to_excel(w, index=False, sheet_name="artists")
        meta.to_excel(w, index=False, sheet_name="meta")
        if len(df_errors):
            df_errors.to_excel(w, index=False, sheet_name="errors")

    print("\n==================== Ø®Ù„Ø§ØµÙ‡ Ø§Ø¬Ø±Ø§ ====================")
    print(meta.to_string(index=False))
    print("out_file:", out_xlsx)
    print("====================================================\n")

    # ===== 7) Ø¢Ù¾Ù„ÙˆØ¯ Ø¨Ù‡ Ø¯Ø±Ø§ÛŒÙˆ =====
    drive_link = None
    try:
        service = build_drive()
        file = drive_upload(service, out_xlsx, DRIVE_FOLDER_ID, share_anyone=True)
        drive_link = file.get("webViewLink")
        print("âœ… Drive upload OK:", drive_link)

        meta2 = meta.copy()
        meta2["drive_file_id"] = file.get("id")
        meta2["drive_webViewLink"] = drive_link
        with pd.ExcelWriter(out_xlsx, engine="openpyxl", mode="a", if_sheet_exists="replace") as w:
            meta2.to_excel(w, index=False, sheet_name="meta")
    except Exception as e:
        print("âš ï¸ Drive upload error:", e)

    # ===== 8) ØªÙ„Ú¯Ø±Ø§Ù… =====
    try:
        coffee = "â˜•"
        msg = (
            f"Ø³Ù„Ø§Ù… Ø¢Ù‚Ø§ÛŒ Ø´Ù…Ø³ØŒ Ø¨ÙØ±Ù…Ø§ÛŒÛŒØ¯ Ù‚Ù‡ÙˆØªÙˆÙ† {coffee}\n\n"
            f"Ø§ÛŒÙ†Ù… Ø®Ù„Ø§ØµÙ‡â€ŒÛŒ Ú¯Ø²Ø§Ø±Ø´ Ø§Ù…Ø±ÙˆØ²:\n"
            f"ØªØ§Ø±ÛŒØ®: {timestamp}\n"
            f"Ø¢Ø±ØªÛŒØ³Øªâ€ŒÙ‡Ø§ÛŒ Ù…ÙˆÙÙ‚: {ok_count}/{n}\n"
            f"ØªÙØ±ÙÚ©â€ŒÙ‡Ø§: {tracks_total} | Ø¢Ù„Ø¨ÙˆÙ…â€ŒÙ‡Ø§: {albums_total}\n"
            f"Ø®Ø·Ø§Ù‡Ø§: {errors_total}\n"
            f"Ø²Ù…Ø§Ù† Ø§Ø¬Ø±Ø§: {elapsed:.1f} Ø«Ø§Ù†ÛŒÙ‡\n"
        )
        if drive_link:
            msg += f"\nÙ„ÛŒÙ†Ú© Ø¯Ø±Ø§ÛŒÙˆ: {drive_link}"
        tg_send_text(msg)
        tg_send_document(out_xlsx, caption=f"ğŸ“ ÙØ§ÛŒÙ„ Ú©Ø§Ù…Ù„ ({timestamp})")
    except Exception as e:
        print("âš ï¸ Telegram error:", e)

    print(f"âœ… Done â†’ {out_xlsx}")

if __name__ == "__main__":
    main()
